Comparing clustering methods, K-means and Gaussian mixture models

1. Use stats::kmeans on the zip.test.gz data set. Plot the sum of
   squared errors (tot.withinss, within-point scatter) as a function
   of K, for K=1 to 20 clusters. After what K does the squared
   error start to look flat?

2. Use mclust::Mclust to fit Gaussian mixture models, for G=1 to 20
   mixture components. Plot the log likelihood as a function of G
   (number of mixture components). After what G does the log
   likelihood start to look flat?
- if mclust::Mclust does not work for you (some students reported it
  returns NULL), it may be because your data set is in the wrong
  format (make sure it is a numeric matrix). You can also try using
  another package that implements Gaussian mixture models,
  e.g. Rmixmod, mixture, EMCluster, mixtools, bgmm, flexmix.

3. For both models above, use pdfCluster::adj.rand.index to compute
   the Adjusted Rand Index (ARI) with respect to the true class/digit
   labels (1 means perfect clustering and values near 0 mean random
   clusters). Make a plot of ARI versus number of mixture components,
   each algorithm in a different color (e.g. kmeans=black,
   Mclust=red). What is the best value of ARI that you observed? What
   algorithm, and how many components?

Please submit your code along with your figures and commentary in a
single PDF.

** For CS599 graduate students only:

Code the K-means algorithm from scratch based on the pseudo-code in
the textbooks. Start by taking K random data points as the initial K
cluster centers (use base::sample for random selection). 
- Write a function KMEANS(data.matrix, K) which returns a list similar
  to the result of the stats::kmeans function. 
- Make a figure that compares the within-point scatter (tot.withinss
  element of the resulting list) for the two kmeans algorithms. Plot
  tot.withinss as a function of K, using two random starts for each
  algorithm (there should be four points plotted per K, with different
  algorithms in different colors). To reduce repetition in your code
  please use three nested for loops: (1) K=1 to 20, (2)
  algorithm=yours or stats::kmeans, (3) random seed=1 or 2, e.g.

#+BEGIN_SRC R
  algo.list <- list(mine=KMEANS, stats=stats::kmeans)
  ss.dt.list <- list()
  for(K in 1:20){
    for(algo.name in names(algo.list)){
      for(seed in 1:2){
	set.seed(seed)
	algo.fun <- algo.list[[algo.name]]
	result.list <- algo.fun(X, K)
	ss.dt.list[[paste(K, algo.name, seed)]] <- data.table(
	  K, algo.name, seed, error=result.list$tot.withinss)
      }
    }
  }
#+END_SRC

